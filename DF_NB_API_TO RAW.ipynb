{"cells":[{"cell_type":"code","source":["spark.conf.set(\"spark.microsoft.delta.optimizeWrite.enabled\", \"true\")\n","spark.conf.set(\"spark.microsoft.delta.optimizeWrite.binSize\", \"1073741824\")\n","spark.conf.set(\"spark.sql.parquet.int96RebaseModeInRead\", \"LEGACY\")\n","spark.conf.set(\"spark.sql.parquet.int96RebaseModeInWrite\", \"LEGACY\")\n","spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"CORRECTED\")\n","from pyspark.sql.functions import col, when\n","from pyspark.sql import functions as F\n","from pyspark.sql.types import DataType\n","from datetime import datetime\n","import re\n","import os\n","import pandas as pd\n","\n","# Define the path to your JSON file\n","file_path = \"/lakehouse/default/Files/api_data.json\"\n","\n","# Load JSON data into a Pandas DataFrame\n","df = pd.read_json(file_path)\n","spark_df = spark.createDataFrame(df)\n","\n","# Add \"nav_\" prefix and convert to lowercase\n","final_table_name = f\"bronze_api_data\"\n","\n","# Save the DataFrame as a Delta table with column mapping mode 'name' and schema merge enabled\n","spark_df.write.format(\"delta\").mode(\"overwrite\")\\\n","    .option(\"delta.columnMapping.mode\", \"name\")\\\n","    .option(\"mergeSchema\", \"true\")\\\n","    .saveAsTable(final_table_name)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":14,"statement_ids":[14],"livy_statement_state":"available","session_id":"49874dcd-b21e-475f-b061-e527f8982bae","state":"finished","normalized_state":"finished","queued_time":"2024-08-01T06:41:19.9004187Z","session_start_time":null,"execution_start_time":"2024-08-01T06:41:20.2860894Z","execution_finish_time":"2024-08-01T06:41:47.8362927Z","parent_msg_id":"7556577e-9561-4ebf-8052-759a28cb6fa3"},"text/plain":"StatementMeta(, 49874dcd-b21e-475f-b061-e527f8982bae, 14, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/opt/spark/python/lib/pyspark.zip/pyspark/sql/pandas/conversion.py:428: UserWarning: createDataFrame attempted Arrow optimization because 'spark.sql.execution.arrow.pyspark.enabled' is set to true; however, failed by the reason below:\n  Could not convert '' with type str: tried to convert to double\nAttempting non-optimization as 'spark.sql.execution.arrow.pyspark.fallback.enabled' is set to true.\n"]}],"execution_count":12,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"49d08922-efec-463c-be65-1f6ec54ccd7b"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default"},"synapse_widget":{"version":"0.1","state":{}},"dependencies":{"lakehouse":{"default_lakehouse":"48bd7c32-ade2-40fe-aa6f-aa1acf6eca87","known_lakehouses":[{"id":"48bd7c32-ade2-40fe-aa6f-aa1acf6eca87"}],"default_lakehouse_name":"DE_LH_RAW","default_lakehouse_workspace_id":"830b357e-c1db-481a-88a8-91cfdd31edcc"}}},"nbformat":4,"nbformat_minor":5}